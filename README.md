# Metamodelo de Predicci√≥n de Direcci√≥n de Precios de Commodities

**Prueba T√©cnica - Modelador Junior**

## üìë Tabla de Contenidos

- [Descripci√≥n del Proyecto](#descripci√≥n-del-proyecto)
- [Estructura del Proyecto](#estructura-del-proyecto)
- [Datos](#datos)
- [Metodolog√≠a](#metodolog√≠a)
- [Resultados](#resultados)
- [Conclusiones](#conclusiones)
- [Instalaci√≥n y Uso](#instalaci√≥n-y-uso)
- [Dependencias](#dependencias)

---

## Descripci√≥n del Proyecto

Desarrollo de un metamodelo de clasificaci√≥n que predice la direcci√≥n (subida/bajada) de precios de commodities utilizando las predicciones de 3 modelos base optimizados (AA6KBD, IPBG4J, OBONV1), espec√≠ficamente para horizontes de 4 semanas.

### üéØ Resultados Clave

- **Modelo**: Random Forest Classifier
- **Accuracy**: 82.35% (14/17 predicciones correctas)
- **F1-Score**: 76.92%
- **Recall**: 100% (captura todas las subidas)
- **Dataset**: 56 registros, 28 features, 0 valores nulos
- **Modelos base**: 3 de 5 (selecci√≥n por cobertura >50%)

### Problema de Negocio

Dado un conjunto de predicciones de m√∫ltiples modelos sobre el precio futuro de un commodity, determinar si el precio real ser√° mayor o menor que el precio actual, permitiendo tomar decisiones de trading informadas basadas en el consenso y dispersi√≥n de las predicciones.

### Variable Objetivo

- **`direction_real = 1`**: Si el precio SUBE (precio_futuro > precio_actual)
- **`direction_real = 0`**: Si el precio BAJA o se mantiene (precio_futuro ‚â§ precio_actual)

---

## Estructura del Proyecto

```
/Users/christian/Prueba/
‚îú‚îÄ‚îÄ notebooks/                          # Jupyter notebooks organizados
‚îÇ   ‚îú‚îÄ‚îÄ 01_analisis_exploratorio.ipynb # EDA completo
‚îÇ   ‚îú‚îÄ‚îÄ 02_preparacion_datos.ipynb     # Limpieza y preparaci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ 03_feature_engineering.ipynb   # Creaci√≥n de features
‚îÇ   ‚îú‚îÄ‚îÄ 04_modelado_clasificacion.ipynb # Entrenamiento y evaluaci√≥n
‚îÇ   ‚îî‚îÄ‚îÄ 05_evaluacion_resultados.ipynb # An√°lisis final y conclusiones
‚îÇ
‚îú‚îÄ‚îÄ data/                               # Datos del proyecto
‚îÇ   ‚îú‚îÄ‚îÄ raw/                            # Datos originales
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ReportDataALL_20250404 (1).xlsx
‚îÇ   ‚îú‚îÄ‚îÄ processed/                      # Datos procesados
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dataset_completo.csv        # 56 registros, 8 columnas (3 modelos)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ dataset_final.csv           # 56 registros, 33 columnas (28 features)
‚îÇ   ‚îî‚îÄ‚îÄ results/                        # Modelos entrenados
‚îÇ       ‚îú‚îÄ‚îÄ modelo_final.pkl            # Random Forest entrenado (134KB)
‚îÇ       ‚îú‚îÄ‚îÄ scaler.pkl                  # StandardScaler (2.1KB)
‚îÇ       ‚îî‚îÄ‚îÄ imputer.pkl                 # SimpleImputer (1.5KB) [legacy]
‚îÇ
‚îú‚îÄ‚îÄ outputs/                            # Resultados y visualizaciones
‚îÇ   ‚îî‚îÄ‚îÄ figures/                        # Gr√°ficos generados (6 figuras)
‚îÇ       ‚îú‚îÄ‚îÄ 01_serie_temporal_precios.png
‚îÇ       ‚îú‚îÄ‚îÄ 02_distribucion_horizontes.png
‚îÇ       ‚îú‚îÄ‚îÄ 03_analisis_errores_modelos.png
‚îÇ       ‚îú‚îÄ‚îÄ 04_cambios_precio.png
‚îÇ       ‚îú‚îÄ‚îÄ 05_correlacion_features.png
‚îÇ       ‚îî‚îÄ‚îÄ 06_feature_importance.png
‚îÇ
‚îú‚îÄ‚îÄ Prueba T√©cnica - Modelador Junior.pdf  # Documento de requisitos
‚îú‚îÄ‚îÄ README.md                           # Este archivo (documentaci√≥n completa)
‚îú‚îÄ‚îÄ requirements.txt                    # Dependencias Python
‚îú‚îÄ‚îÄ .gitignore                          # Archivos ignorados por Git
‚îî‚îÄ‚îÄ .dockerignore                       # Archivos ignorados por Docker
```

---

## Datos

### Fuente de Datos

**Archivo**: `ReportDataALL_20250404.xlsx`

#### Hoja "Real"

- **66 registros** de precios hist√≥ricos
- **Per√≠odo**: 2023-12-21 a 2025-04-03
- **Commodity**: Granular (fertilizante)
- **Rango de precios**: $201.69 - $392.39

#### Hoja "Predicted"

- **1,704 registros** de predicciones
- **5 modelos originales**: AA6KBD, HFWV8N, IPBG4J, LFHXNV, OBONV1
- **3 modelos seleccionados**: AA6KBD, IPBG4J, OBONV1 (cobertura >50%)
- **M√∫ltiples horizontes temporales**: 7-56 d√≠as

### Dataset Final

Despu√©s del procesamiento y optimizaci√≥n:

- **56 registros** con predicciones a 4 semanas (27-29 d√≠as)
- **3 modelos base** seleccionados por cobertura de datos
- **28 features** creadas mediante feature engineering
- **0 valores nulos** gracias a imputaci√≥n inteligente
- **Dataset limpio**: Split 70% train (39) / 30% test (17)

---

## Metodolog√≠a

### 1. An√°lisis Exploratorio (EDA)

**Notebook 01**: `01_analisis_exploratorio.ipynb`

- An√°lisis de distribuci√≥n temporal de precios
- Comportamiento de cada modelo base
- Identificaci√≥n de patrones y correlaciones
- An√°lisis de errores por modelo
- **Visualizaciones**: 3 GraficoS

**Hallazgos clave**:

- Precios con volatilidad moderada (CV = 20%)
- Variabilidad significativa entre modelos
- Oportunidad clara para metamodelo

### 2. Preparaci√≥n de Datos

**Notebook 02**: `02_preparacion_datos.ipynb`

#### Proceso de Optimizaci√≥n

**An√°lisis de Cobertura por Modelo:**

- AA6KBD: 77% cobertura ‚úì
- IPBG4J: 77% cobertura ‚úì
- OBONV1: 100% cobertura ‚úì
- HFWV8N: 46% cobertura ‚úó (eliminado)
- LFHXNV: 30% cobertura ‚úó (eliminado)

**Decisi√≥n T√©cnica:**
Se eliminaron HFWV8N y LFHXNV por baja cobertura (<50%), lo que habr√≠a generado imputaci√≥n masiva y sesgo en el metamodelo.

#### Pasos Realizados

- **Filtrado**: Horizonte temporal de 4 semanas (27-29 d√≠as)
- **Selecci√≥n**: 3 modelos con cobertura >50%
- **Pivoteo**: Convertir formato largo a ancho (1 columna por modelo)
- **Imputaci√≥n inteligente**: Forward fill + mediana por modelo
- **Uni√≥n**: Merge con precios reales (actual y futuro)
- **Variable objetivo**: Creaci√≥n de `direction_real`
- **Validaciones**: 0 nulos, sin duplicados

**Resultado**: Dataset limpio de 56 registros con 3 predicciones por fila (0 valores nulos)

### 3. Feature Engineering

**Notebook 03**: `03_feature_engineering.ipynb`

#### Features creadas (28 totales):

**A. Features por Modelo** (9 features = 3 √ó 3 modelos)

- Cambio absoluto: `predicci√≥n - precio_actual`
- Cambio porcentual: `(cambio / precio_actual) √ó 100`
- Direcci√≥n predicha: `1` si predice subida, `0` si no

**B. Features Agregadas** (6 features)

- `avg_prediction`: Media de predicciones
- `median_prediction`: Mediana
- `std_prediction`: Desviaci√≥n est√°ndar
- `min_prediction`, `max_prediction`: Valores extremos
- `range_prediction`: Rango de predicciones

**C. Features de Consenso** (5 features)

- `consensus_direction`: Direcci√≥n mayoritaria
- `consensus_bullish`: Cantidad de modelos que predicen subida
- `consensus_bearish`: Cantidad que predicen bajada
- `consensus_mixed`: Indicador de desacuerdo
- `direction_agreement`: Grado de acuerdo (0-1)

**D. Features de Dispersi√≥n** (5 features)

- `avg_change`: Cambio promedio predicho
- `avg_pct_change`: Cambio porcentual promedio
- `std_change`, `std_pct_change`: Dispersi√≥n de cambios
- `prediction_confidence`: Confianza (1 / (1 + std))

**E. Features de Diferencias entre Modelos** (3 features)

- Diferencias entre pares de modelos para capturar divergencias

**An√°lisis de correlaci√≥n**: Identificaci√≥n de features m√°s prometedoras

#### Visualizaciones Generadas

1. **01_serie_temporal_precios.png**: Evoluci√≥n temporal de precios reales
2. **02_distribucion_horizontes.png**: Distribuci√≥n de horizontes de predicci√≥n
3. **03_analisis_errores_modelos.png**: An√°lisis de errores por modelo base
4. **04_cambios_precio.png**: Distribuci√≥n de cambios de precio
5. **05_correlacion_features.png**: Matriz de correlaci√≥n entre features
6. **06_feature_importance.png**: Top 5 features m√°s importantes (generado en notebook 04)

### 4. Modelado y Clasificaci√≥n

**Notebook 04**: `04_modelado_clasificacion.ipynb`

#### Configuraci√≥n

- **Split**: 70% entrenamiento, 30% test (sin validaci√≥n cruzada, seg√∫n requisitos)
- **Orden temporal**: Sin shuffle para mantener consistencia temporal
- **Preprocesamiento**: StandardScaler para normalizaci√≥n

#### Modelos Evaluados

**Modelo 1: Logistic Regression**

- Regularizaci√≥n L2
- `max_iter=1000`
- Coeficientes como feature importance

**Modelo 2: Random Forest**

- `n_estimators=100`
- `max_depth=5`
- Feature importances nativas

#### Selecci√≥n del Modelo

- **Criterio**: F1-Score (balance entre precisi√≥n y recall)
- **Modelo seleccionado**: [Se determina en ejecuci√≥n]

#### Feature Importance - Top 5

Identificaci√≥n y visualizaci√≥n de las 5 variables m√°s importantes para el modelo final.

### 5. Evaluaci√≥n y Resultados

**Notebook 05**: `05_evaluacion_resultados.ipynb`

#### M√©tricas de Evaluaci√≥n (Requisitos)

- **Accuracy**: Proporci√≥n de aciertos generales
- **Precision**: Precisi√≥n en predicciones positivas
- **Recall**: Capacidad de detectar subidas
- **F1-Score**: Media arm√≥nica (balance)
- **R2 Score**: Capacidad explicativa

#### An√°lisis de Performance

- Matriz de confusi√≥n detallada
- An√°lisis de errores (FP, FN)
- Curvas ROC y Precision-Recall
- Interpretabilidad del modelo

---

## Resultados

### Modelo Final

**Random Forest Classifier** (Seleccionado por mejor F1-Score)

#### M√©tricas de Performance (Test Set: 17 registros)

- **Accuracy**: 82.35%
- **Precision**: 62.50%
- **Recall**: 100.00%
- **F1-Score**: 76.92%
- **R2 Score**: 0.1649

#### Matriz de Confusi√≥n

```
              Predicho
              Baja  Sube
Real  Baja     9     3
      Sube     0     5
```

**Interpretaci√≥n:**

- El modelo captura TODAS las subidas reales (Recall 100%)
- Clasifica correctamente 14 de 17 casos (82.35% accuracy)
- Genera 3 falsos positivos (predice subida cuando baja)
- 0 falsos negativos (no pierde ninguna oportunidad de subida)
- Mejor desempe√±o que Logistic Regression

### Top 5 Features M√°s Importantes

1. **avg_pct_change** (0.1251): Cambio porcentual promedio predicho por los 3 modelos
2. **AA6KBD_pct_change** (0.1164): Cambio porcentual predicho por el modelo AA6KBD
3. **avg_change** (0.1051): Cambio absoluto promedio predicho
4. **IPBG4J_change** (0.1044): Cambio absoluto predicho por el modelo IPBG4J
5. **IPBG4J_pct_change** (0.0839): Cambio porcentual predicho por el modelo IPBG4J

**Insight clave:** Las features de cambio porcentual y las predicciones de modelos individuales (especialmente AA6KBD e IPBG4J) son las m√°s determinantes para predecir la direcci√≥n del precio.

---

## Conclusiones

### Resumen Ejecutivo

1. **Modelo exitoso con 82.35% de accuracy**: El Random Forest logr√≥ predecir correctamente 14 de 17 movimientos de precio en el test set, con un Recall perfecto (100%) para detectar subidas y F1-Score de 76.92%.
2. **Optimizaci√≥n de modelos base crucial**: La eliminaci√≥n de modelos con baja cobertura (HFWV8N, LFHXNV) y la imputaci√≥n inteligente permitieron un dataset limpio de 56 registros con 0 valores nulos, sin comprometer la calidad predictiva.
3. **Features de cambio porcentual dominan**: Las 5 caracter√≠sticas m√°s importantes est√°n relacionadas con cambios porcentuales y predicciones de modelos individuales (AA6KBD, IPBG4J), validando la importancia de capturar tanto el consenso como las se√±ales individuales.
4. **Trade-off Precision-Recall favorable**: Aunque la precisi√≥n es moderada (62.5%), el Recall del 100% significa que el modelo NO PIERDE ninguna oportunidad de subida, ideal para estrategias conservadoras de trading donde es cr√≠tico no perder oportunidades alcistas.

### Limitaciones Identificadas

- **Dataset moderado**: 56 registros (39 train, 17 test) limitan la capacidad de generalizaci√≥n
- **Un solo commodity**: Resultados espec√≠ficos para fertilizante Granular
- **Horizonte fijo**: Solo predicciones a 4 semanas
- **3 modelos base**: Reducci√≥n de 5 a 3 modelos por cobertura de datos

### Pr√≥ximos Pasos Recomendados

1. **Recolecci√≥n de datos**: Ampliar el hist√≥rico para mejorar robustez estad√≠stica
2. **Multi-commodity**: Expandir a otros commodities para validar generalizaci√≥n
3. **Ensemble avanzado**: Probar XGBoost, LightGBM o stacking con validaci√≥n cruzada
4. **M√∫ltiples horizontes**: Adaptar a predicciones de 1, 2, 3 y 4 semanas simult√°neamente
5. **Monitoreo continuo**: Implementar pipeline de reentrenamiento autom√°tico con nuevos datos

---

## Instalaci√≥n y Uso

### Instalaci√≥n Local

#### Requisitos Previos

- Python 3.9+
- pip o conda

#### Instalaci√≥n

```bash
# Clonar repositorio
git clone git@github.com:Christ02/precios_de_commodities.git
cd precios_de_commodities

# Crear entorno virtual (recomendado)
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate

# Instalar dependencias
pip install -r requirements.txt
```

#### Ejecuci√≥n

```bash
# Iniciar Jupyter Notebook
jupyter notebook notebooks/

# O ejecutar notebooks en orden:
# 1. 01_analisis_exploratorio.ipynb
# 2. 02_preparacion_datos.ipynb
# 3. 03_feature_engineering.ipynb
# 4. 04_modelado_clasificacion.ipynb
# 5. 05_evaluacion_resultados.ipynb
```

### Uso del Modelo Entrenado

```python
# Cargar modelo y scaler guardados
import joblib
import pandas as pd

# Cargar artefactos (134KB modelo + 2.1KB scaler)
modelo = joblib.load('data/results/modelo_final.pkl')
scaler = joblib.load('data/results/scaler.pkl')

# Cargar datos (debe tener las 28 features)
df = pd.read_csv('data/processed/dataset_final.csv')

# Separar features (28 columnas) de metadata (5 columnas)
exclude = ['date_requested', 'date_prediction', 'direction_real', 
           'value_at_request', 'value_at_prediction']
X = df[[c for c in df.columns if c not in exclude]]

# Escalar y predecir
X_scaled = scaler.transform(X)
predicciones = modelo.predict(X_scaled)
probabilidades = modelo.predict_proba(X_scaled)

# Ejemplo de predicci√≥n individual
idx = 0
print(f"Fecha: {df.iloc[idx]['date_requested']} -> {df.iloc[idx]['date_prediction']}")
print(f"Precio actual: ${df.iloc[idx]['value_at_request']:.2f}")
print(f"Direcci√≥n predicha: {'SUBE ‚Üë' if predicciones[idx] == 1 else 'BAJA ‚Üì'}")
print(f"Confianza: {max(probabilidades[idx]):.2%}")
print(f"Direcci√≥n real: {'SUBE ‚Üë' if df.iloc[idx]['direction_real'] == 1 else 'BAJA ‚Üì'}")
```

---

## Dependencias

Ver `requirements.txt` para lista completa. Dependencias del proyecto:

```
pandas==2.1.4          # Manipulaci√≥n de datos
numpy==1.26.2          # Operaciones num√©ricas
matplotlib==3.8.2      # Visualizaciones
seaborn==0.13.0        # Gr√°ficos estad√≠sticos
scikit-learn==1.3.2    # Machine Learning
openpyxl==3.1.2        # Lectura de Excel
jupyter==1.0.0         # Notebooks interactivos
joblib==1.3.2          # Serializaci√≥n de modelos
```

---

## Estructura de Commits

El proyecto sigue una estructura de commits organizada y profesional:

1. `Initial commit: project structure and configuration`
2. `Agregar an√°lisis exploratorio de datos completo`
3. `Agregar preparaci√≥n y limpieza de datos`
4. `Actualizar notebooks 01 y 02: Limpieza y optimizaci√≥n`
5. `Agregar ingenier√≠a de caracter√≠sticas (notebook 03)`
6. `Agregar modelado y clasificaci√≥n (notebook 04)` [Pendiente]
7. `Agregar evaluaci√≥n final y conclusiones (notebook 05)` [Pendiente]
8. `Actualizar README con resultados completos` [Pendiente]

## Autor

**Christian Barrios**
Modelador Junior Candidate

- Email: barriosc31@gmail.com | christianbarrios@ufm.edu
- LinkedIn: Christian Barrios
